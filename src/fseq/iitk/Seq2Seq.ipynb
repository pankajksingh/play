{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML as Function Approximation\n",
    "* **Function** : An Intro\n",
    "* **Neural Network** : A function approximator\n",
    "* **Learning example** : How to Add?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to functions\n",
    "\n",
    "What is a function?\n",
    "- maps input to output\n",
    "- can be thought as a curve or a table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function as a table\n",
    "x = np.arange(0,4*np.pi,0.1)   # start,stop,step\n",
    "y = np.sin(x)\n",
    "list_xy = list(zip(x, y)) \n",
    "df_xy = pd.DataFrame(list_xy, columns = ['x', 'y=sin(x)'])  \n",
    "df_xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function as a curve\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y=sin(x)')\n",
    "plt.title('sine curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data for linear regression\n",
    "beta=10\n",
    "n=50\n",
    "std_dev=100\n",
    "\n",
    "x = np.random.rand(n) * 100\n",
    "e = np.random.randn(n) * std_dev\n",
    "y = x * beta + e\n",
    "#list_xy = list(zip(x, y)) \n",
    "#df_xy = pd.DataFrame(list_xy, columns = ['x', 'y'])  \n",
    "#df_xy.head()\n",
    "\n",
    "# plot data\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('radomly generated 2d points')\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use linear algebra to find best fit line\n",
    "#convert data into matrix and vector\n",
    "X_mat=np.vstack((np.ones(len(x)), x)).T\n",
    "Y=y\n",
    "\n",
    "#calculate coefficients for the best fit line\n",
    "beta_hat = np.linalg.inv(X_mat.T.dot(X_mat)).dot(X_mat.T).dot(Y)\n",
    "yhat = X_mat.dot(beta_hat)\n",
    "                 \n",
    "# plot data and predictions\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Best fit line for sample 2d points')\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, yhat, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Neural Network (Universal Function Approximators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data with labels(i.e. x and y values), we would like to approximate a function f(x) which is very close to y\n",
    "\n",
    "|Scenario|Data=(x,y)|Function=f(x)|\n",
    "|---|---|---|\n",
    "| Best fit line| 2D points  | line approximating 2D points  |\n",
    "| Image classification | pixels representing picture  | class of image e.g. dog, cat   |\n",
    "| Audio2Text  | wave representing utterances  | words  |\n",
    "| Translation  | sentences in multiple languages  | Translator function  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for a machine that can generate functions given dataset representing x and y.\n",
    "[Universal Approximation Theorem](https://medium.com/analytics-vidhya/you-dont-understand-neural-networks-until-you-understand-the-universal-approximation-theorem-85b3e7677126) gives us re-assurance that such a machine exists in our midst.\n",
    ">_It states that a neural network with one hidden layer containing a sufficient but finite number of neurons can approximate any continuous function to a reasonable accuracy, under certain conditions for activation functions (namely, that they must be sigmoid-like)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Windows**\n",
    "\n",
    "**Artificial Neuron**\n",
    "<img src=\"images\\BioNeuron.png\" />\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "**Artificial Neural Network**\n",
    "<img src=\"images\\NeuralNetwork.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linux**\n",
    "<br />\n",
    "\n",
    "**Artificial Neuron**\n",
    "<img src=\"images/BioNeuron.png\" />\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "**Artificial Neural Network**\n",
    "<img src=\"images/NeuralNetwork.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology \n",
    "* Data : (x,y) x is input vector, y is label or output vector. e.g. 2D points.\n",
    "* Batch : Subset of data that is processed in one pass through the network. \n",
    "* $\\hat{y}$ : Approximating function that gets us close to y given x. Also referred as f(x) or f(w,x) where w is to be learnt. e.g red line in linear regression.\n",
    "* Weights : Values of parameters learnt by the network represented by w. e.g. coefficients of best fit line.\n",
    "* Loss : A function defined over the batch data that measures how far are we from the labels, a measure of _y-$\\hat{y}$_. So this is function over approximating function f(x). e.g. summation of sqaure loss over all 2D points.\n",
    "* Backprop : Process of adjusting weights by using the gradient of loss function to come up with better weights\n",
    "* Optimizer : Process that assists us to quickly find optimal values of weight so as to minimize loss. This relies on back-propagation.\n",
    "* Criterion : A human readable measure of model quality. Criterion:Human = Loss: NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deveopment Loops\n",
    "> We run development loop to come up with the desired approximating function given data. There are 2 loops, inner and outer\n",
    "> * **Inner**:\n",
    "> Take a step closer towards desired function by processing a subset of data. This is one pass through the neural network.\n",
    ">* **Outer**\n",
    "> Take a step closer towards desired function by processing all available data. We say that 1 epoch has elapsed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner Loop\n",
    "\n",
    "***\n",
    "$\\mathbf{\\text{Learning objective}}$<br/>\n",
    "***\n",
    "\\begin{align}\n",
    "w^{*} = \\underset{w}{\\textrm{arg min}} \\; L(y,\\hat{y}) \\\\\n",
    "w^{*} = \\underset{w}{\\textrm{arg min}} \\; L(y,f(w,x))\n",
    "\\end{align}\n",
    "\n",
    "***\n",
    "$\\mathbf{\\text{Back Prop}}$<br/>\n",
    "***\n",
    "1.&emsp;Initialize model with random weights $$w = w_{0}$$\n",
    "2. For m = 1 to epochs:<br>\n",
    "(a)&emsp;Run forward pass by estimating output given current weights $$\\hat{y} = f(x,w)$$ \n",
    "(b)&emsp;Calculate loss based on the difference between estimated and real outputs. b is batch size. Square loss is an example of simple loss function. $$ L = \\sum \\limits_{j=1}^b (y-\\hat{y})^2 $$ \n",
    "(c)&emsp;Calculate loss gradient with respect to weight and use it to update the weight parameter. Alpha is step size. $$ w = w - \\nabla_{w} L * \\alpha $$\n",
    "(d)&emsp;Stop when Loss is very small or when patience runs out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Loop\n",
    "* Split data into 3 parts : train, validate, test\n",
    "* For each epoch, build model(aka approximate function) using training data. Then use validate to see the quality of model. Rinse, Repeat.\n",
    "* Finally, run prediction against test data to see how good the model generalizes\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addition as a mono-lingual translation task \n",
    "> Learning how to add using translation function <br/>\n",
    "> 2 + 3 =5\n",
    "\n",
    "* data = (2+3, 5)\n",
    "* function = add(x1,x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_2numbers(a=100000, b=999999):\n",
    "    \"\"\" sample integers from a uniform distribution \"\"\"\n",
    "    \n",
    "    left = random.randint(a,b)\n",
    "    right = random.randint(a,b)\n",
    "                           \n",
    "    return (left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_algebraic_sequence(left, right, op='+' ):\n",
    "    if op=='+':\n",
    "        answer = left + right\n",
    "        lhs = \"{0}+{1}\".format(left, right)\n",
    "        rhs =  \"{0}\".format(answer)\n",
    "    elif op=='-':\n",
    "        answer = left + right\n",
    "        lhs = \"{0}-{1}\".format(answer, right)\n",
    "        rhs =  \"{0}\".format(left)\n",
    "    \n",
    "    return (lhs, rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_algebraic_list(num):\n",
    "    data_list=[]\n",
    "    for i in range(num):\n",
    "        x,y = get_random_2numbers()\n",
    "        lhs, rhs = get_sample_algebraic_sequence(x, y) \n",
    "        data_list.append([lhs,rhs])\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data\n",
    "data_list = get_sample_algebraic_list(100000)\n",
    "data_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data in a dataframe\n",
    "df = pd.DataFrame(data_list, columns=['x','y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_addspace(df, columns_in, save_copy=True):\n",
    "    \"\"\" Adds space between each character \"\"\"\n",
    "\n",
    "    for column_in in columns_in:     \n",
    "        text_processed = df[column_in].apply(lambda s : \" \".join(s))\n",
    "\n",
    "        column_processed = column_in      \n",
    "        #If column is not to be replaced, save the original column with underscore\n",
    "        if(save_copy==True):\n",
    "            column_in_copy = '_' + column_in\n",
    "            df = df.assign(**{column_in_copy: df[column_in]})\n",
    "\n",
    "        df = df.assign(**{column_processed: text_processed})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add space and treat each number as a word\n",
    "df1= text_addspace(df, ['x','y'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset into train, validate and test\n",
    "train, validate, test = np.split(df1.sample(frac=1), [int(.7*len(df1)), int(.9*len(df1))])\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify data folder to save input data\n",
    "work_dir=os.getcwd()\n",
    "print(\"Current working directory is: {0}\".format(work_dir))\n",
    "data_dirpath = os.path.join(work_dir, 'data')\n",
    "print(\"Data directory is: {0}\".format(data_dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create file paths to save data in 3 sets (train, test, validate). text contains input sequence, summary is output sequence\n",
    "train_summary_filepath = os.path.join(data_dirpath, 'train.summary')\n",
    "train_text_filepath    = os.path.join(data_dirpath, 'train.text')\n",
    "valid_summary_filepath = os.path.join(data_dirpath, 'valid.summary')\n",
    "valid_text_filepath    = os.path.join(data_dirpath, 'valid.text')\n",
    "test_summary_filepath  = os.path.join(data_dirpath, 'test.summary')\n",
    "test_text_filepath     = os.path.join(data_dirpath, 'test.text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save file on disk\n",
    "train.to_csv(train_summary_filepath, columns =['y'], header=False, index=False)\n",
    "train.to_csv(train_text_filepath, columns =['x'], header=False, index=False)\n",
    "validate.to_csv(valid_summary_filepath, columns =['y'], header=False, index=False)\n",
    "validate.to_csv(valid_text_filepath, columns =['x'], header=False, index=False)\n",
    "test.to_csv(test_summary_filepath, columns =['y'], header=False, index=False)\n",
    "test.to_csv(test_text_filepath, columns =['x'], header=False, index=False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training using fairseq in a terminal. Pick command for your operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process\n",
    "# windows\n",
    "! fairseq-preprocess --source-lang text --target-lang summary --trainpref data\\train --validpref data\\valid --testpref data\\test --destdir databin --workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process\n",
    "# linux\n",
    "! fairseq-preprocess --source-lang text --target-lang summary --trainpref data/train --validpref data/valid --testpref data/test --destdir databin --workers 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "#windows or linux\n",
    "! fairseq-train databin --lr 0.0001 --lr-scheduler inverse_sqrt --warmup-init-lr 1e-07 --warmup-updates 1000 \\\n",
    "                        --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 --optimizer adam  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "                        --skip-invalid-size-inputs-valid-test --keep-last-epochs 10 --max-epoch 15 --arch lstm \\\n",
    "                        --save-dir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate\n",
    "#windows\n",
    "! fairseq-generate databin --path checkpoint\\checkpoint_best.pt --gen-subset test --skip-invalid-size-inputs-valid-test \\\n",
    "                 --batch-size 128 --beam 5 --min-len 1 --nbest 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate\n",
    "#linux\n",
    "! fairseq-generate databin --path checkpoint/checkpoint_best.pt --gen-subset test --skip-invalid-size-inputs-valid-test \\\n",
    "                 --batch-size 128 --beam 5 --min-len 1 --nbest 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive\n",
    "#windows\n",
    "! fairseq-interactive databin --path checkpoint\\checkpoint_best.pt --beam 5 --min-len 1 --nbest 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive\n",
    "#linux\n",
    "! fairseq-interactive databin --path checkpoint/checkpoint_best.pt --beam 5 --min-len 1 --nbest 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitk",
   "language": "python",
   "name": "iitk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
