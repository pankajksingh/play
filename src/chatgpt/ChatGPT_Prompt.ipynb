{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT and the era of prompting\n",
        "This talk will cover what is ChatGPT and how to use it.\n",
        "\n",
        "* ChatGPT Evolution : From neural network to large language model\n",
        "* ChatGPT Usage     : From fine-tuning to zero-shot learning\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2soEYE22VoG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT Evolution\n",
        "We will introduce the notion of function and then show that GPT and ChatGPT are complex functions that can do certain tasks for us.\n",
        "* Function(Traditional vs AI)\n",
        "* GPT & ChatGPT as a function"
      ],
      "metadata": {
        "id": "ld7L1GzobGNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function(Traditional)\n",
        "We typically think of an application as a collection of tasks. These tasks can be achieved by writing function. Function is a very general concept and we have been writing it for ages. A function takes an input and produces an ouput. We typically write function body to do such a transformation."
      ],
      "metadata": {
        "id": "Mx4bRVjRPP2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function(AI)\n",
        "With the advent of deep learning, we have a new way to write a function. Instead of explicitly writing functions, we collect a pair of inputs(**x**) and outputs(**y**).  We feed x to an untrained deep learning model **f**. f transforms x to **y'** which is our prediction. We find the gap between y(ground truth) and y'(prediction) and use this gap as a feedback mechanism. When we say model is learning, model is tweaking its internal parameters w to produce outputs closer to ground truth. So f is in-fact f(w,x) and we are learning write **w** such that y'= f(w,x) is in fact very close to y. Once training is complete, w is frozen and we can start inference on a new x to produce new y.\n",
        "\n",
        "<br/>\n",
        "\n",
        "![NeuralNet](https://drive.google.com/uc?export=view&id=1Tiwy1JJdP3Mu6URLVn1xjL0r8JQ0hbcv)\n",
        "\n"
      ],
      "metadata": {
        "id": "WMiVg6FbOzKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained Models(aka functions)\n",
        "Since we have a general mechanism of writing function, practitioners have built models(functions) that can do certain kinds of mapping. Just like container images, we can download these models from the hub and do inference on them. This however assumes that what you want to achieve is available in the model hub.\n",
        "\n",
        "|Task|Pre-trained model(f)|x|y|\n",
        "|---|---|---|--- |\n",
        "| Sentiment Analysis| distilbert-base-uncased-finetuned-sst-2-english  | text  |  sentiment(+ve, -ve) |\n",
        "| Summarizer| sshleifer/distilbart-cnn-12-6  | text  |  summary |\n",
        "| Generator| gpt2  | text  |  continuation text |\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "Typically, our applications require us to do novel tasks which may not be directly available in the hub. What are our options?\n",
        "\n",
        "|Function metaphor|AI task| Considerations |\n",
        "|---|---| ---|\n",
        "| Write _new_ function| Training from scratch | Costly in compute and data  | \n",
        "| _Refactor_ existing function| Fine-tuning existing model| Moderate requirements on new data and compute  | \n",
        "| _Pass custom function_ to pre-existing function| Few shot learning, inference time conditioning | Cheapest, require large models, no training  |\n",
        "\n",
        "<br/>\n",
        "\n",
        "GPT and ChatGPT are models that do not require new training for a novel task.They can just be conditioned at inference time by providing right prompt. These models are from a family of models called LLM(Large Language Model). Let us get to know these models(functions) a little bit better.\n",
        "\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "G6KvPXIbPOZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT\n",
        "\n",
        "GPT is a large language model. \n",
        "\n",
        "* Large : GPT is large as it has large number of parameters. GPT-3 has 175 billion parameters. Large models have shown to be adept at doing tasks other than they were trained on. This is achieved via few shot learning.\n",
        "\n",
        "* Language model : GPT is a language model which is trained on large amount of text from the internet. The training task involves predicting next token given starting context. Once training is complete, GPT is able to spit out meaningful continuations from the starting text. \n",
        "\n",
        "So, GPT is a function that takes an input prompt and produces a response that continues the input. So given input _The sun is a huge_, GPT may produce a valid continuation as _star present at the centre of the solar system_. \n",
        "\n",
        "GPT stands for _Generative Pretrained Transformer_. It is generative as it generates new text. It is pre-trained as the model weights are frozen before we use it. Transfomer refers to a deep learning architecture that allows us to develop large language models like GPT.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O2kOWrldWKHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### GPT vs ChatGPT\n",
        "GPT model continues a given text but that is not very useful. We would like to have an AI assistant. So we need a modified language model. This is achieved via fine-tuning GPT.\n",
        "\n",
        "* Supervised fine tuning: SFT\n",
        "* RL based fine tuning : RLHF or Reinforcement Learning From Human Feedback\n",
        "\n",
        "First we teach GPT to chat. This is done by feeding conversation data say from Reddit. The model is asked to continue like a conversation. After this phase the model can chat.\n",
        "\n",
        "Secondly, we want the model to listen to instructions and respond in a way that is valued highly by humans. This is done via RLHF where model receives high score for producing helpful, honest and harmless responses.\n",
        "\n",
        "At the end of these phases, we have transformed GPT into ChatGPT. Once ChatGPT is ready, all weights are frozen. "
      ],
      "metadata": {
        "id": "4DztVXKtb_wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT usage\n",
        "\n",
        "We will revisit ways to obtaining a function for a novel task. How can we go about leveraging ChatGPT?\n",
        "\n",
        "|Options| Considerations |\n",
        "|---|---|\n",
        "| Write _new_ ChatGPT| Very costly in data, compute, expertise. More than $50M. Big companies doing it.  | \n",
        "| _Fine tune_ ChatGPT| Less costly but not readily available. You take a copy of your model in your cluster and use your data to fine-tune. | \n",
        "| _Prompt_ ChatGPT   | Cheapest, require no training but need to learn on how to prompt  |"
      ],
      "metadata": {
        "id": "ygdWK1pedfw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few shot learning\n",
        "Large language models exhibit this property that they do a good job at doing novel tasks without retraining. You can provide prompt at inference time to guide the model to do a certain task. It is as-if the model has already learnt a myriad of tasks and is waiting for you to provide the right prompt. \n",
        "\n",
        "![Few-Shot](https://drive.google.com/uc?export=view&id=1c4EnbgGit9hUzN7GWmObjjUMCudH0GxJ)"
      ],
      "metadata": {
        "id": "I6z0BJrqfClj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Anatomy\n",
        "\n",
        "Prompt is a way to elicit desired response from ChatGPT. ChatGPT can be treated like an alien that communicates in certain way and prompt is a way to communicate with it.  Prompt has certain components, not all mandatory.\n",
        "\n",
        "* __Instruction__: a specific task or instruction you want the model to perform\n",
        "* __Context__: can involve external information or additional context that can steer the model to better responses\n",
        "* __Input Data__: is the input or question that we are interested to find a response for\n",
        "* __Output Indicator__: indicates the type or format of the output.\n",
        "\n",
        "<br/>\n",
        "For e.g., in the above example we have following pieces.\n",
        "\n",
        "* Instruction: Translate English to French:\n",
        "* Context: sample examples like sea otter => loutre de ner\n",
        "* Input Data: cheese =>\n",
        "* Output Indicator: Not used\n",
        "\n",
        "Look at some guidance on how to build prompt at [Prompting Guide](https://www.promptingguide.ai/). "
      ],
      "metadata": {
        "id": "M-EDdXYve-QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt samples \n",
        "Let us review samples of prompt and response from ChatGPT. Keep an eye on the prompt anatomy. Please visit https://chat.openai.com/chat to try more."
      ],
      "metadata": {
        "id": "10Q0z3ecoli6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt-Fact\n",
        "\n",
        "![Factoid](https://drive.google.com/uc?export=view&id=1V02_Abcug80RdSRi7HNyr1VB73nDld7m)\n",
        "\n"
      ],
      "metadata": {
        "id": "X-YcQsbDoHqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt-Sentiment Analysis\n",
        "\n",
        "![Sentiment Analysis](https://drive.google.com/uc?export=view&id=1gPJKAFiJTz4AmkucZzjFFx0RVSeEIjG_)\n"
      ],
      "metadata": {
        "id": "PJBRlYiFpVlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt-Reading Comprehension\n",
        "\n",
        "![Sentiment Analysis](https://drive.google.com/uc?export=view&id=10i95JvM3-OCqSDeJnwQvZSGxbWfHWOb8)\n"
      ],
      "metadata": {
        "id": "0jvML4I5pg74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt-Maths Reasoning\n",
        "\n",
        "![Sentiment Analysis](https://drive.google.com/uc?export=view&id=1rBLnRcZoYWoaVgQ082yRaHRiKDz66VxZ)\n"
      ],
      "metadata": {
        "id": "5Pr4wbyAp3qI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt-Coding\n",
        "\n",
        "![Sentiment Analysis](https://drive.google.com/uc?export=view&id=1JghmGZx150xf_pUd2iNePp4KXiPPpytD)\n"
      ],
      "metadata": {
        "id": "x06K2mm5qLs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limitations\n",
        "ChatGPT gives us impressive capabilities without retraining initial model. That said, it still has few challenges.\n",
        "  * __Prompt engineering__ : We are still learning how to elicit best response from ChatGPT by doing appropriate prompt engineering. Users may not be able to talk in the language of ChatGPT. This means that we need to _design_ the right prompt for the right task. This can be cumbersome. So there are various efforts in the direction of _**Automatic** Prompt Engineering_ where we would like to automate generation of prompts.\n",
        "\n",
        "  * __Prompt size__ : ChatGPT limits the prompt size to 4000 tokens that amounts to around 3000 words. This limits how much context can be provided at inference time. In future, we expect this limitation to be mitigated.\n",
        "\n",
        "  * __Hallucination__ : ChatGPT has no notion of session. In multi-turn scenario, we pass the snapshot of conversation till that time to ChatGPT to maintain the session. For longer session, ChatGPT has been observed to make facts which is commonly termed as hallucination. One way to mitigate this problem is to teach ChatGPT to call APIs for tasks it is not good at. OpenAI has released [plugins](https://openai.com/blog/chatgpt-plugins) models to do that. With the help of ChatGPT plugins, a user can interact with ChatGPT in natural language and ChatGPT can talk to [WolframAlpha](https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/) and help you learn Physics, Chemistry & Maths. You may watch the [chemistry example](https://www.youtube.com/watch?v=EOQV9VakBgE&t=1948s)"
      ],
      "metadata": {
        "id": "nvyj_oYTqt0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions?"
      ],
      "metadata": {
        "id": "kYKoh6K2w5r1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appendix\n",
        "\n",
        "Ignore the content below. This is just a filler to allow pdf export.\n",
        "\n",
        "Essay on Solar System and Planets (300 words)\n",
        "Introduction\n",
        "\n",
        "Our solar system was formed billions of years ago. It consists of numerous celestial bodies including planets, satellites, asteroids, comets, meteorites and a massive star. Our solar system forms a part of the Milky Way Galaxy. Various celestial bodies in our solar system revolve around the Sun directly or indirectly.\n",
        "\n",
        "The Formation of the Solar System\n",
        "\n",
        "It is believed that around 4.6 billion years ago, the gravitational collapse of a giant interstellar molecular cloud gave shape to our solar system. Major part of the collapsing mass collated at the centre, that formed the Sun. The remaining mass flattened into a proto planetary disk and formed the planets, satellites and other objects in the solar system. Planet Jupiter, the biggest planet in our solar system, contains major chunk of the remaining mass.\n",
        "\n",
        "Our solar system is believed to have evolved substantially since its inception. Many new moons have come into shape from the gases and dust around the planets. Several collisions among the celestial bodies have also occurred and still continue to occur thereby contributing to the evolution of the solar system.\n",
        "\n",
        "The Discovery of Planets\n",
        "\n",
        "For thousands of years astronomers believed that Earth was stationary and formed the centre of the universe. It was in the 18th century that the astronomers accepted that Earth orbits around the Sun.\n",
        "\n",
        "In 2nd millennium BC, Mercury, Venus, Mars, Jupiter and Saturn were identified by ancient Babylonian astronomers. Later, Nicolaus Copernicus also identified them. Uranus was discovered by famous astronomer, Sir William Herschel in 1781. Neptune was discovered by English astronomer and mathematician, John Couch Adams in the year 1846. It was in the year 1930 that the ninth planet, Pluto was discovered. Astronomer Clyde Tombaugh discovered Pluto which is now identified as a dwarf planet.\n",
        "\n",
        "Conclusion\n",
        "\n",
        "The study of the universe and heavenly bodies is one of the most fascinating studies. Through continuous research, astronomers have found out several surprising facts about the universe and our solar system. Our solar system is ever evolving and newer facts are being discovered and studied by researchers year after year."
      ],
      "metadata": {
        "id": "gQ57wF1XxUYX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgMt67Csx_LD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}