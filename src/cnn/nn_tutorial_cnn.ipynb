{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0ed269c4732129800d279d66eeb1523fdd99996f395d59ffc6aa8212cb85608cf",
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ed269c4732129800d279d66eeb1523fdd99996f395d59ffc6aa8212cb85608cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ML for Images\n",
    "* **Refresher** : ML Problem Formulation\n",
    "* **CNN** : History & Intution\n",
    "* **Learning example** : How to recognize digit?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ML Problem Formulation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Inner Loop\n",
    "\n",
    "***\n",
    "$\\mathbf{\\text{Learning objective}}$<br/>\n",
    "***\n",
    "Given data (x,y) find weights (w) such that f(w,x) is close to y. \n",
    "We say that we learnt model f with parameters w. \n",
    "Loss L measures gap between reality and prediction and is used by model as feedback.\n",
    "\n",
    "\\begin{align}\n",
    "w^{*} = \\underset{w}{\\textrm{arg min}} \\; L(y,\\hat{y}) \\\\\n",
    "w^{*} = \\underset{w}{\\textrm{arg min}} \\; L(y,f(w,x))\n",
    "\\end{align}\n",
    "\n",
    "***\n",
    "$\\mathbf{\\text{Back Prop}}$<br/>\n",
    "***\n",
    "1.&emsp;Initialize model with random weights $$w = w_{0}$$\n",
    "2. For m = 1 to epochs:<br>\n",
    "(a)&emsp;Run forward pass by estimating output given current weights $$\\hat{y} = f(x,w)$$ \n",
    "(b)&emsp;Calculate loss based on the difference between estimated and real outputs. b is batch size. Square loss is an example of simple loss function. $$ L = \\sum \\limits_{j=1}^b (y-\\hat{y})^2 $$ \n",
    "(c)&emsp;Calculate loss gradient with respect to weight and use it to update the weight parameter. Alpha is step size. $$ w = w - \\nabla_{w} L * \\alpha $$\n",
    "(d)&emsp;Stop when Loss is very small or when patience runs out\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Linux**\n",
    "<br />\n",
    "\n",
    "**Artificial Neuron**\n",
    "<img src=\"images/BioNeuron.png\" />\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "**Artificial Neural Network**\n",
    "<img src=\"images/NeuralNetwork.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Optimizer steps along a loss landscape**\n",
    "<img src=\"images/loss-optimizer.gif\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Loss landscape for popular architecture**\n",
    "\n",
    "<br />\n",
    "\n",
    "*VGG*\n",
    "<img src=\"images/loss-vgg.png\" width=\"500\" height=\"600\" />\n",
    "\n",
    "<br />\n",
    "\n",
    "*Resnet*\n",
    "<img src=\"images/loss-resnet.png\" width=\"500\" height=\"600\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolution Neural Net : History & Intution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Lenet-5 : CNN for recognizing digits**\n",
    "<img src=\"images/lenet5.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Hubel & Weisel cat experiment\n",
    "\n",
    "**Observations**\n",
    "* the neurons fired only when the line was in a particular place on the retina.\n",
    "* the activity of these neurons changed depending on the orientation of the line.\n",
    "* sometimes the neurons fired only when the line was moving in a particular direction.\n",
    "\n",
    "**Findings**\n",
    "* there is a topographical map in the visual cortex that represents the visual field, where nearby cells process information from nearby visual fields.  \n",
    "* neurons in the visual cortex are arranged in a precise architecture.  Cells with similar functions are organized into columns, tiny computational machines that relay information to a higher region of the brain.\n",
    "\n",
    "**Learnings**\n",
    "* Introduce filters to process local visual information.\n",
    "* Build higher level abstractions in the network architecture.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Hubel Wiesel Cat Experiment**\n",
    "<img src=\"images/hubel-wiesel.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Visualize CNN : Zeiler and Fergus**\n",
    "\n",
    "*Layer 1-2*\n",
    "<img src=\"images/cnn-layer1-2.png\" />\n",
    "\n",
    "*Layer 3*\n",
    "<img src=\"images/cnn-layer3.png\" />\n",
    "\n",
    "*Layer 4-5*\n",
    "<img src=\"images/cnn-layer4-5.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Recognize handwritten digits using CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from pathlib import Path\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from pytorch_model_summary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data in memory\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ( (x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot sample numpy array as image\n",
    "sample_index = 7\n",
    "\n",
    "pyplot.imshow(x_train[sample_index].reshape((28,28)),cmap=\"gray\")\n",
    "print(y_train[sample_index])\n",
    "print(x_train.shape)\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform numpy data into tensors \n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train,y_train, x_valid, y_valid))\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(type(x_train))\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap data to get access to iterator\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    \"\"\" Returns data loader given batch size. Training is shuffled. Validation batch size is doubled \"\"\"\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=2*bs)\n",
    "\n",
    "    return (train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    \"\"\" \n",
    "        Data goes through forward pass and the output is compared to labels to find loss.\n",
    "        Backward pass in executed if optimizer is given as in the training stage \n",
    "    \"\"\"\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    \"\"\" \n",
    "    Data is fit to model and the model improves from the loss feedback during training stage. \n",
    "    Validation stage considers model static. \n",
    "    \"\"\"\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums))/np.sum(nums)\n",
    "        writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global data\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broker : Avoids hardcoding between data(input schema) & model\n",
    "# This is achieved by keeping the input data transformation within the preprocess method. \n",
    "# WrappedDataLoader thus abstracts tranformation to 4 part tensor that is needed for the model.\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "source": [
    "nn.Sequential\n",
    "------------------------\n",
    "\n",
    "``torch.nn`` has another handy class we can use to simplify our code:\n",
    "`Sequential <https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential>`_ .\n",
    "A ``Sequential`` object runs each of the modules contained within it, in a\n",
    "sequential manner. This is a simpler way of writing our neural network.\n",
    "\n",
    "To take advantage of this, we need to be able to easily define a\n",
    "**custom layer** from a given function.  For instance, PyTorch doesn't\n",
    "have a `view` layer, and we need to create one for our network. ``Lambda``\n",
    "will create a layer that we can then use when defining a network with\n",
    "``Sequential``.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    \"\"\" Custom class inheriting from nn.Module with a forward method so that it can be used as a Layer in the Sequential class\"\"\"\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a CNN model\n",
    "# Avoid hardcoding by having a custom last layer that returns a tensor with shape (bs=batch_size, 10=probability_digit)\n",
    "# Avoid hardcoding by having last but one AdaptiveAvgPool layer that adapts input to produce output of shape 1*1. \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize model layers assuming batch-size of 1\n",
    "\n",
    "# show input shape\n",
    "print(summary(model, torch.zeros((1, 1, 28, 28)), show_input=True))\n",
    "\n",
    "# show output shape\n",
    "print(summary(model, torch.zeros((1, 1, 28, 28)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot model for tensorboard graph\n",
    "writer = SummaryWriter()\n",
    "bs=64\n",
    "images=torch.zeros((bs, 1, 28, 28))\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables for model & training\n",
    "loss_func = F.cross_entropy\n",
    "lr = 0.5  # learning rate\n",
    "epochs =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer to find weights that minimizes loss efficiently\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Initialize so that training across runs is consistent. Also learning rate can be reduced.\n",
    "# Error less than 0.2 is good\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    \"\"\" \n",
    "        Human readable quality metric. Loss is used by machine for feedback. Accuracy is for humans.\n",
    "        Returns measure of the number of times the model predicted the correct digit.\n",
    "    \"\"\"\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measure model accuracy on a batch, valid has double the size than bs\n",
    "train_dli, valid_dli = get_data(train_ds, valid_ds, bs=64)\n",
    "valid_wdl = WrappedDataLoader(valid_dli, preprocess)\n",
    "xs_b0, y_b0 = next(iter(valid_wdl))\n",
    "print(\"Shape of tensor batch is {0}\".format(xs_b0.shape))\n",
    "digit_accuracy=accuracy(model(xs_b0), y_b0)\n",
    "print(\"Percent accuracy is {0} percent on a batch size of {1} on valid dataset\".format(digit_accuracy*100, 2*bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run inference\n",
    "#Take slice from input tensor; (0:1) points to zeroth sample, (1:2) points to first sample\n",
    "index=9\n",
    "xs_b0_infer= xs_b0[index:index+1, :, :, :]\n",
    "y_b0_infer = y_b0[index]\n",
    "#print(xs_b0_infer.shape)\n",
    "#print(y_b0_infer)\n",
    "\n",
    "#prediction probs\n",
    "y_out= model(xs_b0_infer)\n",
    "print(\"Model predicted probability for the image is\\n{0}\\n\".format(y_out))\n",
    "\n",
    "#predicted digit\n",
    "y_pred = torch.argmax(y_out, dim=1)\n",
    "print(\"Model predicts digit {0}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot to visually observe the sample\n",
    "pyplot.imshow(xs_b0_infer.reshape((28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}