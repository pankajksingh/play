{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0ed269c4732129800d279d66eeb1523fdd99996f395d59ffc6aa8212cb85608cf",
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ed269c4732129800d279d66eeb1523fdd99996f395d59ffc6aa8212cb85608cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ML for Images\n",
    "* **Refresher** : ML Problem Formulation\n",
    "* **CNN** : History & Intution\n",
    "* **Learning example** : How to recognize digit?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ML Problem Formulation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Inner Loop\n",
    "\n",
    "***\n",
    "$\\mathbf{\\text{Learning objective}}$<br/>\n",
    "***\n",
    "Given data (x,y) find weights (w) such that f(w,x) is close to y. \n",
    "We say that we learnt model f with parameters w. \n",
    "Loss L measures gap between reality and prediction and is used by model as feedback.\n",
    "\n",
    "\\begin{align}\n",
    "w^{*} = \\underset{w}{\\textrm{arg min}} \\; L(y,\\hat{y}) \\\\\n",
    "w^{*} = \\underset{w}{\\textrm{arg min}} \\; L(y,f(w,x))\n",
    "\\end{align}\n",
    "\n",
    "***\n",
    "$\\mathbf{\\text{Back Prop}}$<br/>\n",
    "***\n",
    "1.&emsp;Initialize model with random weights $$w = w_{0}$$\n",
    "2. For m = 1 to epochs:<br>\n",
    "(a)&emsp;Run forward pass by estimating output given current weights $$\\hat{y} = f(x,w)$$ \n",
    "(b)&emsp;Calculate loss based on the difference between estimated and real outputs. b is batch size. Square loss is an example of simple loss function. $$ L = \\sum \\limits_{j=1}^b (y-\\hat{y})^2 $$ \n",
    "(c)&emsp;Calculate loss gradient with respect to weight and use it to update the weight parameter. Alpha is step size. $$ w = w - \\nabla_{w} L * \\alpha $$\n",
    "(d)&emsp;Stop when Loss is very small or when patience runs out\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Linux**\n",
    "<br />\n",
    "\n",
    "**Artificial Neuron**\n",
    "<img src=\"images/BioNeuron.png\" />\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "**Artificial Neural Network**\n",
    "<img src=\"images/NeuralNetwork.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Optimizer steps along a loss landscape**\n",
    "<img src=\"images/loss-optimizer.gif\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Loss landscape for popular architecture**\n",
    "\n",
    "<br />\n",
    "\n",
    "*VGG*\n",
    "<img src=\"images/loss-vgg.png\" width=\"500\" height=\"600\" />\n",
    "\n",
    "<br />\n",
    "\n",
    "*Resnet*\n",
    "<img src=\"images/loss-resnet.png\" width=\"500\" height=\"600\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolution Neural Net : History & Intution"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Lenet-5 : CNN for recognizing digits**\n",
    "<img src=\"images/lenet5.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Hubel & Weisel cat experiment\n",
    "\n",
    "**Observations**\n",
    "* the neurons fired only when the line was in a particular place on the retina.\n",
    "* the activity of these neurons changed depending on the orientation of the line.\n",
    "* sometimes the neurons fired only when the line was moving in a particular direction.\n",
    "\n",
    "**Findings**\n",
    "* there is a topographical map in the visual cortex that represents the visual field, where nearby cells process information from nearby visual fields.  \n",
    "* neurons in the visual cortex are arranged in a precise architecture.  Cells with similar functions are organized into columns, tiny computational machines that relay information to a higher region of the brain.\n",
    "\n",
    "**Learnings**\n",
    "* Introduce filters to process local visual information.\n",
    "* Build higher level abstractions in the network architecture.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Hubel Wiesel Cat Experiment**\n",
    "<img src=\"images/hubel-wiesel.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Visualize CNN : Zeiler and Fergus**\n",
    "\n",
    "*Layer 1-2*\n",
    "<img src=\"images/cnn-layer1-2.png\" />\n",
    "\n",
    "*Layer 3*\n",
    "<img src=\"images/cnn-layer3.png\" />\n",
    "\n",
    "*Layer 4-5*\n",
    "<img src=\"images/cnn-layer4-5.png\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Recognize handwritten digits using CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from pathlib import Path\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from pytorch_model_summary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data in memory\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "    ( (x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n(50000, 784)\n<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-09T16:21:07.810176</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p4acaae4802)\">\n    <image height=\"218\" id=\"image6198282033\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m58df966471\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m58df966471\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m58df966471\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m58df966471\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m58df966471\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m58df966471\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m58df966471\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mb5e197e8da\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5e197e8da\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5e197e8da\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5e197e8da\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5e197e8da\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5e197e8da\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mb5e197e8da\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p4acaae4802\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAN6klEQVR4nO3dX4xc9XnG8ecBNkiQgLxF0IVATQJIDZbqIAtVYIGrAIYVyOTCkS1ANkVsLoJlS5VaCy6CVCKhtqHiBqSNQDFVShTJxDYB5KxMKJSLCIM2sIQm/BGNHfyn4As7wvwxfnuxx9Fi7/xmPTNnzpj3+5FWM3vemTmvxn72nDO/OefniBCAL76Tmm4AQH8QdiAJwg4kQdiBJAg7kMQp/VyZbT76B2oWEZ5teVdbdtvX2/6d7bdsr+/mtQDUy52Os9s+WdLvJV0raaeklyStjIjfFp7Dlh2oWR1b9sslvRUR70TEJ5J+KmlZF68HoEbdhP08STtm/L6zWvY5tsdsb7e9vYt1AehSNx/QzbarcMxuekSMSxqX2I0HmtTNln2npPNn/P5VSe911w6AunQT9pckXWz7QttfkrRC0pbetAWg1zrejY+IQ7bvkrRV0smSHo2I13vWGYCe6njoraOVccwO1K6WL9UAOHEQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETHUzZjcFxyySUta0NDQ8XnXnXVVcX6Qw89VKwfPny4WG/S5s2bW9ZWrFhRfO4nn3zS63Ya11XYbb8r6YCkzyQdiohFvWgKQO/1Ysv+dxHxfg9eB0CNOGYHkug27CHpl7Zftj022wNsj9nebnt7l+sC0IVud+OvjIj3bJ8tacL2/0TE8zMfEBHjksYlyXZ0uT4AHepqyx4R71W3eyX9XNLlvWgKQO91HHbbp9v+ypH7kq6TNNWrxgD0liM627O2/TVNb82l6cOB/4yIH7R5Drvxs7j00kuL9dWrVxfry5cvb1k76aTy3/Nzzz23WLddrHf6/6dpjz32WLG+bt26Yn3//v097Ka3ImLWf7SOj9kj4h1Jf9NxRwD6iqE3IAnCDiRB2IEkCDuQBGEHkuh46K2jlTH0NqstW7YU66Ojo33q5Fhf1KG3dq6++upi/cUXX+xTJ8ev1dAbW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJLSQ+AiYmJYr2bcfa9e/cW64888kix3u4U2W4uJX3FFVcU6+3GunF82LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKczz4ATjml/HWHkZGRjl/7008/LdZ3797d8Wt364wzzijWp6bK0xC0uwx2yaZNm4r1W265pVj/+OOPO1533TifHUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4Hz2AXDo0KFifceOHX3qpL+WLl1arM+bN6+2de/cubNYH+Rx9E613bLbftT2XttTM5YN256w/WZ1W9+/CoCemMtu/I8lXX/UsvWStkXExZK2Vb8DGGBtwx4Rz0vad9TiZZI2VPc3SLq5t20B6LVOj9nPiYhdkhQRu2yf3eqBtsckjXW4HgA9UvsHdBExLmlc4kQYoEmdDr3tsT0iSdVt+RKmABrXadi3SFpV3V8laXNv2gFQl7bns9t+XNISSWdJ2iPp+5I2SfqZpAsk/UHS8og4+kO82V6L3fhkVqxY0bJ25513Fp9b53Xjh4eHi/X9+/fXtu66tTqfve0xe0SsbFH6VlcdAegrvi4LJEHYgSQIO5AEYQeSIOxAEpziiqJ2l1Rev758DtRFF13UsjY0NNRRT3M1OTnZstbuEttfRGzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkHwPz584v12267rVi/5ppretjN5y1evLhYr3PK73anmbYb43/66adb1g4ePNhRTycytuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETbS0n3dGVJLyW9YMGCYn3Lli3F+gUXXNDLdo6LPetVif+szv8/Tz31VLG+bNmy2tZ9Imt1KWm27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOezD4B2Y9nt6nU66aTy9uDw4cO1rfvGG28s1m+44YZi/ZlnnullOye8tlt224/a3mt7asaye23/0fZk9TNab5sAujWX3fgfS7p+luX/HhELq5/WlwQBMBDahj0inpe0rw+9AKhRNx/Q3WX71Wo3f16rB9kes73d9vYu1gWgS52G/WFJX5e0UNIuST9s9cCIGI+IRRGxqMN1AeiBjsIeEXsi4rOIOCzpR5Iu721bAHqto7DbHpnx67clTbV6LIDB0Hac3fbjkpZIOsv2Tknfl7TE9kJJIeldSd+tr8UT39RU+W/hkiVLivVbb721WN+6dWvL2kcffVR8bt3uuOOOlrU1a9b0sRO0DXtErJxl8SM19AKgRnxdFkiCsANJEHYgCcIOJEHYgSS4lDRqdeaZZ7asffDBB1299k033VSsZz3FlUtJA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EASXEoatVq6dGnTLaDClh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfY6GhoZa1q677rric5999tli/eDBgx31NAhuv/32Yv3BBx/sUydohy07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtl8eLFxfo999zTsnbttdcWn3vhhRcW6zt27CjW6zQ8PFysj46OFusPPPBAsX7aaacdd09HtPv+QdPTUZ9o2m7ZbZ9v+1e237D9uu211fJh2xO236xu59XfLoBOzWU3/pCkf4iIv5b0t5K+Z/sbktZL2hYRF0vaVv0OYEC1DXtE7IqIV6r7ByS9Iek8ScskbagetkHSzTX1CKAHjuuY3fZ8Sd+U9GtJ50TELmn6D4Lts1s8Z0zSWJd9AujSnMNu+8uSNkpaFxH77VnnjjtGRIxLGq9eg4kdgYbMaejN9pCmg/6TiHiiWrzH9khVH5G0t54WAfRC2ymbPb0J3yBpX0Ssm7H8XyV9EBH3214vaTgi/rHNaw3sln1ycrJYX7BgQcev/fDDDxfrBw4c6Pi1u9Vu2PCyyy4r1ruZ8vu5554r1tu9bxs3bux43V9kraZsnstu/JWSbpP0mu3Jatndku6X9DPbd0j6g6TlPegTQE3ahj0i/ltSqwP0b/W2HQB14euyQBKEHUiCsANJEHYgCcIOJNF2nL2nK0s6zn4ia/dNyT179hTrTz75ZMva2rVri8/lFNbOtBpnZ8sOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzl5ZuHBhsb5mzZqWtVWrVvW4m955++23i/UPP/ywWH/hhReK9fHx8WJ9amqqWEfvMc4OJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj5Hp556asva6tWri8+97777ivV588oT4G7atKlYn5iYaFnbvHlz8bm7d+8u1nHiYZwdSI6wA0kQdiAJwg4kQdiBJAg7kARhB5KYy/zs50t6TNJfSjosaTwiHrR9r6Q7Jf1f9dC7I+LpNq91wo6zAyeKVuPscwn7iKSRiHjF9lckvSzpZknfkfSniPi3uTZB2IH6tQr7XOZn3yVpV3X/gO03JJ3X2/YA1O24jtltz5f0TUm/rhbdZftV24/anvU7n7bHbG+3vb27VgF0Y87fjbf9ZUn/JekHEfGE7XMkvS8pJP2zpnf1/77Na7AbD9Ss42N2SbI9JOkXkrZGxAOz1OdL+kVEFGc/JOxA/To+EcbT03g+IumNmUGvPrg74tuSuIwoMMDm8mn8YkkvSHpN00NvknS3pJWSFmp6N/5dSd+tPswrvRZbdqBmXe3G9wphB+rH+exAcoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk2l5wssfel/S/M34/q1o2iAa1t0HtS6K3TvWyt79qVejr+ezHrNzeHhGLGmugYFB7G9S+JHrrVL96YzceSIKwA0k0HfbxhtdfMqi9DWpfEr11qi+9NXrMDqB/mt6yA+gTwg4k0UjYbV9v+3e237K9vokeWrH9ru3XbE82PT9dNYfeXttTM5YN256w/WZ1O+scew31dq/tP1bv3aTt0YZ6O9/2r2y/Yft122ur5Y2+d4W++vK+9f2Y3fbJkn4v6VpJOyW9JGllRPy2r420YPtdSYsiovEvYNi+StKfJD12ZGot2/8iaV9E3F/9oZwXEf80IL3dq+Ocxrum3lpNM75aDb53vZz+vBNNbNkvl/RWRLwTEZ9I+qmkZQ30MfAi4nlJ+45avEzShur+Bk3/Z+m7Fr0NhIjYFRGvVPcPSDoyzXij712hr75oIuznSdox4/edGqz53kPSL22/bHus6WZmcc6Rabaq27Mb7udobafx7qejphkfmPeuk+nPu9VE2GebmmaQxv+ujIjLJN0g6XvV7irm5mFJX9f0HIC7JP2wyWaqacY3SloXEfub7GWmWfrqy/vWRNh3Sjp/xu9flfReA33MKiLeq273Svq5pg87BsmeIzPoVrd7G+7nzyJiT0R8FhGHJf1IDb531TTjGyX9JCKeqBY3/t7N1le/3rcmwv6SpIttX2j7S5JWSNrSQB/HsH169cGJbJ8u6ToN3lTUWyStqu6vkrS5wV4+Z1Cm8W41zbgafu8an/48Ivr+I2lU05/Ivy3pniZ6aNHX1yT9pvp5veneJD2u6d26TzW9R3SHpL+QtE3Sm9Xt8AD19h+antr7VU0Ha6Sh3hZr+tDwVUmT1c9o0+9doa++vG98XRZIgm/QAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/w+R5WmeDDnQtgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "#Plot sample numpy array as image\n",
    "sample_index = 7\n",
    "\n",
    "pyplot.imshow(x_train[sample_index].reshape((28,28)),cmap=\"gray\")\n",
    "print(y_train[sample_index])\n",
    "print(x_train.shape)\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\ntorch.Size([50000, 784])\n<class 'torch.Tensor'>\ntensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "#Transform numpy data into tensors \n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train,y_train, x_valid, y_valid))\n",
    "n, c = x_train.shape\n",
    "print(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(type(x_train))\n",
    "print(y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrap data to get access to iterator\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    \"\"\" Returns data loader given batch size. Training is shuffled. Validation batch size is doubled \"\"\"\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=2*bs)\n",
    "\n",
    "    return (train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    \"\"\" \n",
    "        Data goes through forward pass and the output is compared to labels to find loss.\n",
    "        Backward pass in executed if optimizer is given as in the training stage \n",
    "    \"\"\"\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    \"\"\" \n",
    "    Data is fit to model and the model improves from the loss feedback during training stage. \n",
    "    Validation stage considers model static. \n",
    "    \"\"\"\n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums))/np.sum(nums)\n",
    "        writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\" \\nwriter = SummaryWriter()\\n\\nfor n_iter in range(100):\\n    writer.add_scalar('Loss/train', np.random.random(), n_iter)\\n    writer.add_scalar('Loss/test', np.random.random(), n_iter)\\n    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\\n    writer.add_scalar('Accuracy/test', np.random.random(), n_iter) \\n\""
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "\"\"\" \n",
    "writer = SummaryWriter()\n",
    "\n",
    "for n_iter in range(100):\n",
    "    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "    writer.add_scalar('Accuracy/test', np.random.random(), n_iter) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global data\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broker : Avoids hardcoding between data(input schema) & model\n",
    "# This is achieved by keeping the input data transformation within the preprocess method. \n",
    "# WrappedDataLoader thus abstracts tranformation to 4 part tensor that is needed for the model.\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "source": [
    "nn.Sequential\n",
    "------------------------\n",
    "\n",
    "``torch.nn`` has another handy class we can use to simplify our code:\n",
    "`Sequential <https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential>`_ .\n",
    "A ``Sequential`` object runs each of the modules contained within it, in a\n",
    "sequential manner. This is a simpler way of writing our neural network.\n",
    "\n",
    "To take advantage of this, we need to be able to easily define a\n",
    "**custom layer** from a given function.  For instance, PyTorch doesn't\n",
    "have a `view` layer, and we need to create one for our network. ``Lambda``\n",
    "will create a layer that we can then use when defining a network with\n",
    "``Sequential``.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    \"\"\" Custom class inheriting from nn.Module with a forward method so that it can be used as a Layer in the Sequential class\"\"\"\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a CNN model\n",
    "# Avoid hardcoding by having a custom last layer that returns a tensor with shape (bs=batch_size, 10=probability_digit)\n",
    "# Avoid hardcoding by having last but one AdaptiveAvgPool layer that adapts input to produce output of shape 1*1. \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------------------------------------------\n          Layer (type)         Input Shape         Param #     Tr. Param #\n===========================================================================\n              Conv2d-1      [1, 1, 28, 28]             160             160\n                ReLU-2     [1, 16, 14, 14]               0               0\n              Conv2d-3     [1, 16, 14, 14]           2,320           2,320\n                ReLU-4       [1, 16, 7, 7]               0               0\n              Conv2d-5       [1, 16, 7, 7]           1,450           1,450\n                ReLU-6       [1, 10, 4, 4]               0               0\n   AdaptiveAvgPool2d-7       [1, 10, 4, 4]               0               0\n              Lambda-8       [1, 10, 1, 1]               0               0\n===========================================================================\nTotal params: 3,930\nTrainable params: 3,930\nNon-trainable params: 0\n---------------------------------------------------------------------------\n---------------------------------------------------------------------------\n          Layer (type)        Output Shape         Param #     Tr. Param #\n===========================================================================\n              Conv2d-1     [1, 16, 14, 14]             160             160\n                ReLU-2     [1, 16, 14, 14]               0               0\n              Conv2d-3       [1, 16, 7, 7]           2,320           2,320\n                ReLU-4       [1, 16, 7, 7]               0               0\n              Conv2d-5       [1, 10, 4, 4]           1,450           1,450\n                ReLU-6       [1, 10, 4, 4]               0               0\n   AdaptiveAvgPool2d-7       [1, 10, 1, 1]               0               0\n              Lambda-8             [1, 10]               0               0\n===========================================================================\nTotal params: 3,930\nTrainable params: 3,930\nNon-trainable params: 0\n---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Visualize model layers assuming batch-size of 1\n",
    "\n",
    "# show input shape\n",
    "print(summary(model, torch.zeros((1, 1, 28, 28)), show_input=True))\n",
    "\n",
    "# show output shape\n",
    "print(summary(model, torch.zeros((1, 1, 28, 28)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot model for tensorboard graph\n",
    "writer = SummaryWriter()\n",
    "bs=64\n",
    "images=torch.zeros((bs, 1, 28, 28))\n",
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables for model & training\n",
    "loss_func = F.cross_entropy\n",
    "lr = 0.5  # learning rate\n",
    "epochs =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer to find weights that minimizes loss efficiently\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 0.4438926838874817\n",
      "1 0.44553573632240295\n",
      "2 0.45621789371967314\n",
      "3 0.42846098709106445\n",
      "4 0.4634598870754242\n",
      "5 0.4105317938566208\n",
      "6 0.4437451243162155\n",
      "7 0.4237474972963333\n",
      "8 0.4372615681409836\n",
      "9 0.43016823930740355\n"
     ]
    }
   ],
   "source": [
    "#TODO: Initialize so that training across runs is consistent. Also learning rate can be reduced.\n",
    "# Error less than 0.2 is good\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    \"\"\" \n",
    "        Human readable quality metric. Loss is used by machine for feedback. Accuracy is for humans.\n",
    "        Returns measure of the number of times the model predicted the correct digit.\n",
    "    \"\"\"\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of tensor batch is torch.Size([128, 1, 28, 28])\nPercent accuracy is 96.875 percent on a batch size of 128 on valid dataset\n"
     ]
    }
   ],
   "source": [
    "#Measure model accuracy on a batch, valid has double the size than bs\n",
    "train_dli, valid_dli = get_data(train_ds, valid_ds, bs=64)\n",
    "valid_wdl = WrappedDataLoader(valid_dli, preprocess)\n",
    "xs_b0, y_b0 = next(iter(valid_wdl))\n",
    "print(\"Shape of tensor batch is {0}\".format(xs_b0.shape))\n",
    "digit_accuracy=accuracy(model(xs_b0), y_b0)\n",
    "print(\"Percent accuracy is {0} percent on a batch size of {1} on valid dataset\".format(digit_accuracy*100, 2*bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model predicted probability for the image is\ntensor([[0.0000, 0.0000, 0.0000, 9.4775, 0.0000, 0.0000, 2.3401, 0.0000, 0.0000,\n         0.0000]], grad_fn=<ViewBackward>)\n\nModel predicts digit tensor([3])\n"
     ]
    }
   ],
   "source": [
    "#Run inference\n",
    "#Take slice from input tensor; (0:1) points to zeroth sample, (1:2) points to first sample\n",
    "index=45\n",
    "xs_b0_infer= xs_b0[index:index+1, :, :, :]\n",
    "y_b0_infer = y_b0[index]\n",
    "#print(xs_b0_infer.shape)\n",
    "#print(y_b0_infer)\n",
    "\n",
    "#prediction probs\n",
    "y_out= model(xs_b0_infer)\n",
    "print(\"Model predicted probability for the image is\\n{0}\\n\".format(y_out))\n",
    "\n",
    "#predicted digit\n",
    "y_pred = torch.argmax(y_out, dim=1)\n",
    "print(\"Model predicts digit {0}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa516a417c0>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-09T16:23:34.989190</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p3921f10c74)\">\n    <image height=\"218\" id=\"image231dac1a40\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m676be567e4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m676be567e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m676be567e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m676be567e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m676be567e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m676be567e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m676be567e4\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1dd2ef4030\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1dd2ef4030\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1dd2ef4030\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1dd2ef4030\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1dd2ef4030\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1dd2ef4030\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m1dd2ef4030\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p3921f10c74\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "#Plot to visually observe the sample\n",
    "pyplot.imshow(xs_b0_infer.reshape((28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m      \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           Sequential\n",
      "\u001b[0;31mString form:\u001b[0m   \n",
      "Sequential(\n",
      "           (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "           (1): ReLU() <...> e=(2, 2), padding=(1, 1))\n",
      "           (5): ReLU()\n",
      "           (6): AdaptiveAvgPool2d(output_size=1)\n",
      "           (7): Lambda()\n",
      "           )\n",
      "\u001b[0;31mLength:\u001b[0m         8\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "A sequential container.\n",
      "Modules will be added to it in the order they are passed in the constructor.\n",
      "Alternatively, an ordered dict of modules can also be passed in.\n",
      "\n",
      "To make it easier to understand, here is a small example::\n",
      "\n",
      "    # Example of using Sequential\n",
      "    model = nn.Sequential(\n",
      "              nn.Conv2d(1,20,5),\n",
      "              nn.ReLU(),\n",
      "              nn.Conv2d(20,64,5),\n",
      "              nn.ReLU()\n",
      "            )\n",
      "\n",
      "    # Example of using Sequential with OrderedDict\n",
      "    model = nn.Sequential(OrderedDict([\n",
      "              ('conv1', nn.Conv2d(1,20,5)),\n",
      "              ('relu1', nn.ReLU()),\n",
      "              ('conv2', nn.Conv2d(20,64,5)),\n",
      "              ('relu2', nn.ReLU())\n",
      "            ]))\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "?model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}